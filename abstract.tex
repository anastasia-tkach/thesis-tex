%\cleardoublepage

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract (English/Français)}

In our everyday life we interact with the surrounding environment using our hands. A main focus of recent research has been to bring such interaction to virtual objects, such as the ones projected in virtual reality devices, or super-imposed as holograms in AR/MR headsets. For these applications, it is desirable for the tracking technology to be robust, accurate, and have a seamless deployment. In this thesis we address these requirements by proposing an efficient and robust hand tracking algorithm, introducing a hand model representation that strikes a balance between accuracy and performance, and presenting the online algorithm for precise hand calibration.


In the first part we present a robust method for capturing articulated hand motions in real time using a single depth camera. Our system is based on a realtime registration process that accurately reconstructs hand poses by fitting a 3D articulated hand model to depth images. We register the hand model using depth, silhouette, and temporal information. To effectively map low-quality depth maps to realistic hand poses, we regularize the registration with kinematic and temporal priors, as well as a data-driven prior built from a database of realistic hand poses. We present a principled way of integrating such priors into our registration optimization to enable robust tracking without severely restricting the freedom of motion. 

In the second part we propose the use of sphere-meshes as a novel geometric representation for real-time generative hand tracking.  We derive an optimization to non-rigidly deform a template model to fit the user data in a number of poses. This optimization jointly captures the user's static and dynamic hand geometry, thus facilitating high-precision registration. At the same time, the limited number of primitives in the tracking template allows us to retain excellent computational performance. We confirm this by embedding our models in an open source real-time registration algorithm to obtain a tracker steadily running at 60Hz.

In the third part we introduce an online hand calibration method that learns the geometry as the user performs live in front of the camera, thus enabling seamless virtual interaction at the consumer level. The key novelty in our approach is an online optimization algorithm that jointly estimates pose and shape in each frame, and determines the uncertainty in such estimates. This knowledge allows the algorithm to integrate per-frame estimates over time, and build a personalized geometric model of the captured user. Our approach can easily be integrated in state-of-the-art continuous generative motion tracking software. We provide a detailed evaluation that shows how our approach achieves accurate motion tracking for real-time applications, while significantly simplifying the workflow of accurate hand performance capture.

\textbf{Keywords:} non-rigid registration, realtime hand tracking, realtime hand calibration, sphere-meshes, markerless motion capture

% French abstract
\begin{otherlanguage}{french}
\cleardoublepage
\chapter*{Résumé}
\markboth{Résumé}{Résumé}

Dans notre vie quotidienne, nous interagissons avec l'environnement en utilisant nos mains. Un objectif principal de la recherche récente a été d'apporter une telle interaction à des objets virtuels, tels que ceux projetés dans des dispositifs de réalité virtuelle, ou super-imposés comme des hologrammes dans les casques AR / MR. Pour ces applications, il est souhaitable que la technologie de suivi soit robuste, précise et transparente dans le déploiement. Dans cette thèse, nous répondons à ces exigences en fournissant un algorithme de suivi manuel efficace et robuste, en introduisant une représentation manuelle du modèle qui équilibre la précision et la performance, et en présentant l'algorithme en ligne pour un étalonnage manuel précis.

Dans la première partie, nous présentons une méthode robuste pour capturer les mouvements de la main articulée en temps réel en utilisant une caméra de profondeur unique. Notre système est basé sur un processus d'enregistrement en temps réel qui reconstruit avec précision les poses de la main en ajustant un modèle de main 3D articulé aux images de profondeur. Nous enregistrons le modèle de la main en utilisant la profondeur, la silhouette et l'information temporelle. Pour mapper efficacement des cartes de profondeur de basse qualité à des poses de mains réalistes, nous régularisons l'enregistrement avec des priors cinématiques et temporels, ainsi qu'un préréglage basé sur des données construit à partir d'une base de données de poses réalistes. Nous présentons une méthode basée sur des principes pour intégrer ces priors dans notre optimisation d'enregistrement pour permettre un suivi robuste sans restreindre de manière significative la liberté de mouvement.

Dans la seconde partie, nous proposons l'utilisation de mailles-sphères comme nouvelle représentation géométrique pour le suivi génératif en temps réel. Nous dérivons une optimisation pour déformer de manière non rigide un modèle étalon pour adapter les données de l'utilisateur dans un certain nombre de poses. Cette optimisation capture conjointement la géométrie de la main statique et dynamique de l'utilisateur, facilitant ainsi l'enregistrement de haute précision. En même temps, le nombre limité de primitives dans le modèle de suivi nous permet de maintenir d'excellentes performances de calcul. Nous confirmons cela en intégrant nos modèles dans un algorithme d'enregistrement en temps réel et code source ouvert pour obtenir un tracker fonctionnant régulièrement à 60Hz.

Dans la troisième partie, nous introduisons une méthode de calibrage manuel en ligne qui apprend la géométrie lorsque l'utilisateur se produit en direct devant la caméra, permettant ainsi une interaction virtuelle transparente au niveau du consommateur. La nouveauté clé dans notre approche est un algorithme d'optimisation en ligne qui estime conjointement la pose et la forme dans chaque trame, et détermine l'incertitude dans de telles estimations. Cette connaissance permet à l'algorithme d'intégrer les estimations d'images dans le temps et de construire un modèle géométrique personnalisé de l'utilisateur capturé. Notre approche peut facilement être intégrée dans un logiciel de suivi de mouvement continu, à la pointe de la technologie. Nous fournissons une évaluation détaillée qui montre comment notre approche réalise un suivi de mouvement précis pour les applications en temps réel, tout en simplifiant grandement le flux de travail pour une capture précise des performances de la main.

\textbf{Mots-clés}: enregistrement non-rigide, suivi des mains en temps réel, étalonnage manuel en temps réel, maillages de sphères, capture de mouvement sans marqueur.

\end{otherlanguage}

